{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.metrics import Precision, Recall, F1Score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import scipy.stats as stats\n",
    "import scipy.signal as signal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    \n",
    "    for column in ['x', 'y', 'z']:\n",
    "        df[column] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df\n",
    "\n",
    "def segment(df, window_size, step_size):\n",
    "    segments = []\n",
    "    for start in range(0, len(df) - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        segment = df.iloc[start:end]\n",
    "        segments.append(segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_activities(window_size=32, step_size=16):\n",
    "    # window_size =   # 2.5 seconds\n",
    "    # step_size = 20  # 75% overlap\n",
    "\n",
    "    activities_path = 'Final/Activity' #CHANGE THIS BASED OFF FILE PATH\n",
    "    activity_segments = {}\n",
    "\n",
    "    # Iterate over each activity's folder\n",
    "    for activity_name in os.listdir(activities_path):\n",
    "        # print(activity_name)\n",
    "        activity_folder = os.path.join(activities_path, activity_name)\n",
    "        if os.path.isdir(activity_folder):\n",
    "            # Store segments for each activity\n",
    "            activity_segments[activity_name] = []\n",
    "            \n",
    "            # Iterate over each CSV file within the activity's folder\n",
    "            for filename in os.listdir(activity_folder):\n",
    "                if filename.endswith('.csv'):\n",
    "                    file_path = os.path.join(activity_folder, filename)\n",
    "                    \n",
    "                    # Read  CSV file\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    \n",
    "                    # Normalize data\n",
    "                    df_normalized = normalize(df)\n",
    "                    \n",
    "                    # Segment the data using a rolling window\n",
    "                    segments = segment(df_normalized, window_size, step_size)\n",
    "                    \n",
    "                    # Append the segments to the activity's list\n",
    "                    activity_segments[activity_name].extend(segments)\n",
    "    return activity_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_lstm(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "        LSTM(64),\n",
    "        Dense(len(le.classes_), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "    # Predict the labels on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "    # Calculate other classification metrics\n",
    "    metrics_report = classification_report(y_test, y_pred_classes, output_dict=True)\n",
    "    accuracy_from_report = accuracy_score(y_test, y_pred_classes)\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Accuracy (from report): {accuracy_from_report}\")\n",
    "    print(f\"Precision: {metrics_report['weighted avg']['precision']}\")\n",
    "    print(f\"Recall: {metrics_report['weighted avg']['recall']}\")\n",
    "    print(f\"F1-Score: {metrics_report['weighted avg']['f1-score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_rf(activity_segments):\n",
    "    X, y = [], []\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    print(\"segments in suitable format\")\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    #reshape for rf model\n",
    "    X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "    #model stuff\n",
    "    # Define the Random Forest model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    print(\"training model\")\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    #predict on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test,y_pred,average = 'macro')\n",
    "    recall = recall_score(y_test, y_pred, average = 'macro')\n",
    "    f1 = f1_score(y_test, y_pred, average= 'macro')\n",
    "    print(f\"Model accuracy: {accuracy}\")\n",
    "    print(f\"Model precision: {precision}\")\n",
    "    print(f\"Model recall: {recall}\")\n",
    "    print(f\"Model F1 score: {f1}\")\n",
    "    # return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super(F1Score, self).__init__(name = name, **kwargs)\n",
    "        self.precision = Precision()\n",
    "        self.recall = Recall()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.round(tf.nn.sigmoid(y_pred))  # Use sigmoid to convert the output to between 0 and 1, then round to the nearest integer\n",
    "        self.precision.update_state(y_true, y_pred, sample_weight)\n",
    "        self.recall.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        p = self.precision.result()\n",
    "        r = self.recall.result()\n",
    "        return 2 * ((p * r) / (p + r + tf.keras.backend.epsilon()))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.precision.reset_states()\n",
    "        self.recall.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_SVM(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            feature_vector = segment.to_numpy().flatten()\n",
    "            X.append(feature_vector)\n",
    "            y.append(activity_name)\n",
    "    print(\"Segments in suitable format\")\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    y_encoded = np.where(y_encoded > 0, 1, -1)  # Adjust labels to -1 and 1\n",
    "\n",
    "    print(\"Labels encoded\")\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size = 0.2, random_state = 42)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(1, input_shape=(X_train_scaled.shape[1],), activation = None) \n",
    "    ])\n",
    "\n",
    "    def hinge_loss(y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.maximum(1 - y_true * y_pred, 0))\n",
    "\n",
    "    model.compile(optimizer='sgd', loss=hinge_loss, metrics=['accuracy', Precision(), Recall(), F1Score()])\n",
    "\n",
    "    print(\"Compiled model\\nTraining Model\")\n",
    "    model.fit(X_train_scaled, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "    results = model.evaluate(X_test_scaled, y_test)\n",
    "    print(\"Test Results for SVM model - Loss: {:.4f}, Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1 Score: {:.4f}\".format(*results))\n",
    "    \n",
    "    # return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_XGB(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    print('X_train:', X_train.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "    \n",
    "    \n",
    "    # Convert data to DMatrix format for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "    # Define parameters for XGBoost\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',  # Multi-class classification\n",
    "        'num_class': 34,                # Number of classes\n",
    "        'eval_metric': 'merror',         # Evaluation metric: multi-class classification error\n",
    "        'learning_rate': 0.2, \n",
    "        'max_depth': 6, \n",
    "        'n_estimators': 200, \n",
    "        'subsample': 1.0\n",
    "    }\n",
    "\n",
    "# **params\n",
    "    xgb_classifier = xgb.XGBClassifier(**params)\n",
    "    xgb_classifier.fit(X_train, y_train)\n",
    "    # Predict on the test data\n",
    "    y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "    print(f'Test Precision: {precision}')\n",
    "    print(f'Test Recall: {recall}')\n",
    "    print(f'Test F1 Score: {f1}')\n",
    "    \n",
    "    # return xgb_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_lgbm(activity_segments):\n",
    "    X, y = [], []\n",
    "\n",
    "\n",
    "    # Convert the segments into a suitable format for training\n",
    "    for activity_name, segments in activity_segments.items():\n",
    "        for segment in segments:\n",
    "            X.append(segment.to_numpy())  # Assuming segment is a pandas DataFrame\n",
    "            y.append(activity_name)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    print(\"segments in suitable format\")\n",
    "\n",
    "\n",
    "    # Encode the activity labels into integers\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(\"labels encoded\")\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    print('X_train:', X_train.shape)\n",
    "    print('y_train:', y_train.shape)\n",
    "\n",
    "    # Model Training\n",
    "    clf = LGBMClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f'Test Accuracy: {accuracy}')\n",
    "    print(f'Test Precision: {precision}')\n",
    "    print(f'Test Recall: {recall}')\n",
    "    print(f'Test F1 Score: {f1}')\n",
    "    \n",
    "    # return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NO FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEAN FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_mean(input_df):\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return np.mean(input_x), np.mean(input_y), np.mean(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_mean(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STD DEV FITLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_std_dev(input_df):\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return np.std(input_x), np.std(input_y), np.std(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_std_dev(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKEWNESS FILTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_skew(input_df):\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return stats.skew(input_x), stats.skew(input_y), stats.skew(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_skew(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurtosis Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_kurtosis(input_df):\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return stats.kurtosis(input_x), stats.kurtosis(input_y), stats.kurtosis(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_kurtosis(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Crossing Rate Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_zcr(input_df):\n",
    "\n",
    "    def compute_zcr(input_arr):\n",
    "        my_array = np.array(input_arr)\n",
    "        return float(((((my_array[:-1] * my_array[1:]) < 0).sum())/len(input_arr)))\n",
    "\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return compute_zcr(input_x), compute_zcr(input_y), compute_zcr(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = windowed_zcr(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dominant Frequency Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dom_f(input_df):\n",
    "\n",
    "    def compute(input_arr):\n",
    "        frequency_spectrum = np.fft.fft(input_arr)\n",
    "        dom = frequency_spectrum[np.argmax(frequency_spectrum)]\n",
    "        return dom\n",
    "    input_x = np.array(input_df.loc[:, \"x\"])\n",
    "    input_y = np.array(input_df.loc[:, \"y\"])\n",
    "    input_z = np.array(input_df.loc[:, \"z\"])\n",
    "\n",
    "    return compute(input_x), compute(input_y), compute(input_z)\n",
    "\n",
    "def normalize(df):\n",
    "    \n",
    "    x, y, z = dom_f(df)\n",
    "    df = pd.DataFrame(df[['x', 'y', 'z']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [32, 96, 160]  # 1, 1.5, and 2 seconds\n",
    "step_sizes_16 = [2, 6, 10]  # 1/16 overlap for each window size\n",
    "step_sizes_8 = [4, 12, 20]  # 1/8 overlap for each window size\n",
    "step_sizes_4 = [8, 24, 40]  # 1/4 overlap for each window size\n",
    "step_sizes = [step_sizes_16 ,step_sizes_8, step_sizes_4]\n",
    "\n",
    "for index_step in range(3):\n",
    "    for step in range(3):\n",
    "        print(f\"Step:{step_sizes[index_step][step]}  Window:{window_sizes[step]}\")       \n",
    "        activity_segments = segment_activities(window_sizes[step], step_sizes[index_step][step])\n",
    "        print(f\"Finished  Window:{window_sizes[step]} Segmentation\")\n",
    "        print(f\"STARTING LSTM MODEL\")\n",
    "        fit_model_lstm(activity_segments)\n",
    "        print(f\"STARTING RANDOM FOREST MODEL\")\n",
    "        fit_model_rf(activity_segments)\n",
    "        print(f\"STARTING XGB MODEL\")\n",
    "        fit_model_XGB(activity_segments)\n",
    "        print(f\"STARTING SVM MODEL\")\n",
    "        fit_model_SVM(activity_segments)\n",
    "        print(f\"STARTING LGBM MODEL\")\n",
    "        fit_model_lgbm(activity_segments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
